🐍 Python:     MaxKSpmmWrapper          (GNN integration)
               MaxKSpGEMMFunction        (PyTorch autograd)
                     ↓
🔗 C++ Binding: cuda_kernel_bindings.cpp (Python ↔ C++)
                     ↓  
🌉 CUDA Bridge: cuda_kernel_wrappers.cu  (C++ ↔ CUDA)
                     ↓
⚡ CUDA Kernel: spmm_maxk.cu            (Your optimized code)



     print("\n┌─────────────────────────────────────────────────────────┐")
    print("│                    PYTHON LAYER                        │")
    print("│  MaxKSpmmWrapper (Python class)                        │")
    print("│  - Manages metadata loading                             │") 
    print("│  - Provides high-level interface                       │")
    print("│  - Handles graph data conversion                       │")
    print("└─────────────────────┬───────────────────────────────────┘")
    print("                      │ .spmm() method calls")
    print("┌─────────────────────▼───────────────────────────────────┐")
    print("│                PYTORCH AUTOGRAD LAYER                  │")
    print("│  MaxKSpGEMMFunction (PyTorch Function)                 │")
    print("│  - Handles automatic differentiation                   │")
    print("│  - Manages forward/backward pass                       │")
    print("│  - Converts tensors to kernel format                   │")
    print("└─────────────────────┬───────────────────────────────────┘")
    print("                      │ calls maxk_cuda_kernels.*")
    print("┌─────────────────────▼───────────────────────────────────┐")
    print("│                C++ BINDING LAYER                       │")
    print("│  cuda_kernel_bindings.cpp (PyBind11)                   │")
    print("│  - Exposes C++ functions to Python                     │")
    print("│  - Validates tensor arguments                          │")
    print("│  - Manages CUDA memory and errors                      │")
    print("└─────────────────────┬───────────────────────────────────┘")
    print("                      │ calls *_wrapper functions")
    print("┌─────────────────────▼───────────────────────────────────┐")
    print("│                CUDA WRAPPER LAYER                      │")
    print("│  cuda_kernel_wrappers.cu (C++ file)                    │")
    print("│  - Bridges C++ and CUDA                                │")
    print("│  - Handles kernel launch parameters                    │")
    print("│  - Manages CUDA errors                                 │")
    print("└─────────────────────┬───────────────────────────────────┘")
    print("                      │ calls <<<grid, block>>> kernels")
    print("┌─────────────────────▼───────────────────────────────────┐")
    print("│                 ACTUAL CUDA KERNELS                    │")
    print("│  spmm_maxk.cu & spmm_maxk_backward.cu                  │")
    print("│  - Your optimized CUDA kernels                         │")
    print("│  - Actual computation happens here                     │")
    print("│  - Uses warp4 metadata and sparse representation      │")
    print("└─────────────────────────────────────────────────────────┘")


  ┌─────────────────────────────────────────────────────────────┐
│                    GNN Training Script                      │
│                 (maxk_gnn_integrated.py)                   │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│                MaxK SAGE Model                              │
│             (maxk_models_integrated.py)                     │
│  ┌─────────────────┬─────────────────┬─────────────────┐    │
│  │   MaxKSAGE     │ MaxKSAGEConv    │  MaxKSpmvWrapper│    │
│  └─────────────────┴─────────────────┴─────────────────┘    │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│              MaxK SpGEMM Function                           │
│            (maxk_spgemm_function.py)                        │
│  ┌─────────────────┬─────────────────┬─────────────────┐    │
│  │MaxKSpGEMMFunction│ AutoGrad Support│  Fallback Logic │    │
│  └─────────────────┴─────────────────┴─────────────────┘    │
└─────────────────────┬───────────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────────┐
│              Direct CUDA Kernels                           │
│            (maxk_cuda_kernels.so)                          │
│  ┌─────────────────┬─────────────────┬─────────────────┐    │
│  │ spmm_maxk.cu   │spmm_maxk_back.cu│   cuSPARSE      │    │
│  │   (forward)    │   (backward)    │  (fallback)     │    │
│  └─────────────────┴─────────────────┴─────────────────┘    │
└─────────────────────────────────────────────────────────────┘
